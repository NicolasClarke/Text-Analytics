{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared by Yifan Ren, Yinzhe Lu and prof Yilu Zhou.\n",
    "\n",
    "\n",
    "Welcome to Lab 3! By completing the task of detecting scams, this lab will introduce <b>4 classifiers </b>:\n",
    "\n",
    "1. naive bayes\n",
    "2. decision tree\n",
    "3. random forest\n",
    "4. neural network (optional)\n",
    "\n",
    "Also, we introduce <b>3 approaches</b> to construct features:\n",
    "1. Bag-of-words\n",
    "2. TFIDF\n",
    "3. Word2Vec\n",
    "\n",
    "Thus, we will have 12 accuracy results to compare in our final table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.0.0-cp38-cp38-macosx_10_9_x86_64.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/nicolasclarke/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.0.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /Users/nicolasclarke/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.0.0 smart-open-5.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordnet\n",
      "  Downloading wordnet-0.0.1b2.tar.gz (8.8 kB)\n",
      "Collecting colorama==0.3.9\n",
      "  Downloading colorama-0.3.9-py2.py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: wordnet\n",
      "  Building wheel for wordnet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wordnet: filename=wordnet-0.0.1b2-py3-none-any.whl size=10520 sha256=770465a1e954a2e8fb022a0b0cd8144e61b8d2ca7d32cb4c71033e95a79801d8\n",
      "  Stored in directory: /Users/nicolasclarke/Library/Caches/pip/wheels/c3/6b/0d/1364db2ed13d53eba854f1b31dcfb4cc56adc191e11147ed64\n",
      "Successfully built wordnet\n",
      "Installing collected packages: colorama, wordnet\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "Successfully installed colorama-0.3.9 wordnet-0.0.1b2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\n",
      "  Downloading levenshtein-0.12.0-cp38-cp38-macosx_10_14_x86_64.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 3.7 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/nicolasclarke/opt/anaconda3/lib/python3.8/site-packages (from Levenshtein) (50.3.1.post20201107)\n",
      "Installing collected packages: Levenshtein\n",
      "Successfully installed Levenshtein-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nicolasclarke/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Spam Email.csv\", usecols=[\"CATEGORY\", \"MESSAGE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm one of the 30,000 but it's not working ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0</td>\n",
       "      <td>Damien Morton quoted:\\n\\n&gt;W3C approves HTML 4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>0</td>\n",
       "      <td>On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>0</td>\n",
       "      <td>Once upon a time, Manfred wrote :\\n\\n\\n\\n&gt; I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>0</td>\n",
       "      <td>If you run Pick, and then use the \"New FTOC\" b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CATEGORY                                            MESSAGE\n",
       "0            1  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...\n",
       "1            1  ATTENTION: This is a MUST for ALL Computer Use...\n",
       "2            1  This is a multi-part message in MIME format.\\n...\n",
       "3            1  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...\n",
       "4            1  This is the bottom line.  If you can GIVE AWAY...\n",
       "...        ...                                                ...\n",
       "5791         0  I'm one of the 30,000 but it's not working ver...\n",
       "5792         0  Damien Morton quoted:\\n\\n>W3C approves HTML 4 ...\n",
       "5793         0  On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...\n",
       "5794         0  Once upon a time, Manfred wrote :\\n\\n\\n\\n> I w...\n",
       "5795         0  If you run Pick, and then use the \"New FTOC\" b...\n",
       "\n",
       "[5796 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5796 entries, 0 to 5795\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   CATEGORY  5796 non-null   int64 \n",
      " 1   MESSAGE   5796 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info() \n",
    "#no further preprocessing for null values because of no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3900\n",
       "1    1896\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non alphabets\n",
    "remove_non_alphabets = lambda x: re.sub(r'[^a-zA-Z]',' ',x)\n",
    "\n",
    "# tokenn alphabets-only list\n",
    "tokenize = lambda x: word_tokenize(x)\n",
    "\n",
    "# assign ps to a lambda function to run on each line of value\n",
    "ps = PorterStemmer()\n",
    "stem = lambda w: [ ps.stem(x) for x in w ]\n",
    "\n",
    "# assign lemmatizer to a lambda function to run on each line of value\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "leammtizer = lambda x: [ lemmatizer.lemmatize(word) for word in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : [=====] : Completed"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dear homeown interest rate are at their lowest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>attent thi is a must for all comput user new s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thi is a multi part messag in mime format next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>import inform the new domain name are final av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>thi is the bottom line If you can give away CD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY                                            MESSAGE\n",
       "0         1  dear homeown interest rate are at their lowest...\n",
       "1         1  attent thi is a must for all comput user new s...\n",
       "2         1  thi is a multi part messag in mime format next...\n",
       "3         1  import inform the new domain name are final av...\n",
       "4         1  thi is the bottom line If you can give away CD..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply all above methods to the column ''\n",
    "print('Processing : [=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(remove_non_alphabets)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(tokenize)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(stem)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(leammtizer)\n",
    "print('=', end='')\n",
    "data['MESSAGE'] = data['MESSAGE'].apply(lambda x: ' '.join(x))\n",
    "print('] : Completed', end='')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train-Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to 30 percent test data and 70 percent train data\n",
    "# labels can be seen as y, an dependent variable\n",
    "train_corpus, test_corpus, train_labels, test_labels = train_test_split(data[\"MESSAGE\"],\n",
    "                                                                        data[\"CATEGORY\"],\n",
    "                                                                        test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Features for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build bag of words features' vectorizer and get features\n",
    "bow_vectorizer=CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "bow_train_features = bow_vectorizer.fit_transform(train_corpus)\n",
    "bow_test_features = bow_vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tfidf features' vectorizer and get features\n",
    "tfidf_vectorizer=TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=(1,1))\n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(train_corpus)  \n",
    "tfidf_test_features = tfidf_vectorizer.transform(test_corpus)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5fe7cbe57d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tokenize documents for word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m tokenized_train = [nltk.word_tokenize(text)\n\u001b[0;32m----> 3\u001b[0;31m                    for text in train_corpus]\n\u001b[0m\u001b[1;32m      4\u001b[0m tokenized_test = [nltk.word_tokenize(text)\n\u001b[1;32m      5\u001b[0m                    for text in test_corpus]  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# tokenize documents for word2vec\n",
    "tokenized_train = [nltk.word_tokenize(text)\n",
    "                   for text in train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text)\n",
    "                   for text in test_corpus]  \n",
    "\n",
    "# build word2vec model                   \n",
    "wv_model = gensim.models.Word2Vec(tokenized_train,\n",
    "                               size=200,                          #set the size or dimension for the word vectors \n",
    "                               window=60,                        #specify the length of the window of words taken as context\n",
    "                               min_count=10)                   #ignores all words with total frequency lower than 10\n",
    "\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector \n",
    "   \n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "# averaged word vector features from word2vec\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=wv_model,\n",
    "                                                 num_features=200)                   \n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=wv_model,\n",
    "                                                num_features=200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to evaluate our classification models based on four metrics\n",
    "# This defined function is also useful in other cases. This is comparing test_y and pred_y. \n",
    "# Both contain 1s and 0s.\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    metrics_dict = dict(zip([\"accuracy\", \"precision\", \"recall\", \"f1\"], [None]*4))\n",
    "    #metrics_dict = {i:None for i in [\"accuracy\", \"precision\", \"recall\", \"f1\"]}\n",
    "    for m in metrics_dict.keys():\n",
    "        exec('''metrics_dict['{}'] = np.round(                                                    \n",
    "                        metrics.{}_score(true_labels, \n",
    "                                               predicted_labels),\n",
    "                        2)'''.format(m, m))\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an Easy-to-use Function for Train/Test/Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that trains the model, performs predictions and evaluates the predictions\n",
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    # evaluate model prediction performance   \n",
    "    '''get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)'''\n",
    "    print(metrics.classification_report(test_labels,predictions))\n",
    "    return predictions, get_metrics(true_labels=test_labels, predicted_labels=predictions)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # import naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier # import Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test on BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      1179\n",
      "           1       0.98      0.79      0.87       560\n",
      "\n",
      "    accuracy                           0.93      1739\n",
      "   macro avg       0.94      0.89      0.91      1739\n",
      "weighted avg       0.93      0.93      0.92      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign naive bayes function to an object\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# predict and evaluate naive bayes\n",
    "mnb_bow_predictions, mnb_bow_metrics = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1179\n",
      "           1       0.91      0.94      0.93       560\n",
      "\n",
      "    accuracy                           0.95      1739\n",
      "   macro avg       0.94      0.95      0.95      1739\n",
      "weighted avg       0.95      0.95      0.95      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign decision tree function to an object\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# predict and evaluate decision tree\n",
    "dt_bow_predictions, dt_bow_metrics = train_predict_evaluate_model(classifier=dt,\n",
    "                                                               train_features=bow_train_features,\n",
    "                                                               train_labels=train_labels,\n",
    "                                                               test_features=bow_test_features,\n",
    "                                                               test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1179\n",
      "           1       0.98      0.93      0.96       560\n",
      "\n",
      "    accuracy                           0.97      1739\n",
      "   macro avg       0.98      0.96      0.97      1739\n",
      "weighted avg       0.97      0.97      0.97      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assign random forest function to an object\n",
    "rf = RandomForestClassifier(criterion=\"entropy\")\n",
    "\n",
    "# predict and evaluate random forest\n",
    "rf_bow_predictions, rf_bow_metrics = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test on TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      1179\n",
      "           1       0.99      0.67      0.80       560\n",
      "\n",
      "    accuracy                           0.89      1739\n",
      "   macro avg       0.93      0.83      0.86      1739\n",
      "weighted avg       0.90      0.89      0.89      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate naive bayes\n",
    "mnb_tfidf_predictions, mnb_tfidf_metrics = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1179\n",
      "           1       0.91      0.94      0.93       560\n",
      "\n",
      "    accuracy                           0.95      1739\n",
      "   macro avg       0.94      0.95      0.95      1739\n",
      "weighted avg       0.95      0.95      0.95      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate decision tree\n",
    "dt_tfidf_predictions, dt_tfidf_metrics = train_predict_evaluate_model(classifier=dt,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1179\n",
      "           1       0.99      0.92      0.96       560\n",
      "\n",
      "    accuracy                           0.97      1739\n",
      "   macro avg       0.98      0.96      0.97      1739\n",
      "weighted avg       0.97      0.97      0.97      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate random forest\n",
    "rf_tfidf_predictions, rf_tfidf_metrics = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test on Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      1179\n",
      "           1       0.99      0.67      0.80       560\n",
      "\n",
      "    accuracy                           0.89      1739\n",
      "   macro avg       0.93      0.83      0.86      1739\n",
      "weighted avg       0.90      0.89      0.89      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate naive bayes\n",
    "mnb_avgwv_predictions, mnb_avgwv_metrics = train_predict_evaluate_model(classifier=mnb,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1179\n",
      "           1       0.92      0.94      0.93       560\n",
      "\n",
      "    accuracy                           0.95      1739\n",
      "   macro avg       0.95      0.95      0.95      1739\n",
      "weighted avg       0.96      0.95      0.95      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate decision tree\n",
    "dt_avgwv_predictions, dt_avgwv_metrics = train_predict_evaluate_model(classifier=dt,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1179\n",
      "           1       0.99      0.93      0.96       560\n",
      "\n",
      "    accuracy                           0.97      1739\n",
      "   macro avg       0.98      0.96      0.97      1739\n",
      "weighted avg       0.97      0.97      0.97      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate random forest\n",
    "rf_avgwv_predictions, rf_avgwv_metrics = train_predict_evaluate_model(classifier=rf,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Performance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mAccuracy Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.93           0.95           0.97\n",
      "TFIDF                0.89           0.95           0.97\n",
      "Word2Vec             0.89           0.95           0.97\n",
      "\n",
      "\u001b[1;31mPrecision Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.98           0.91           0.98\n",
      "TFIDF                0.99           0.91           0.99\n",
      "Word2Vec             0.99           0.92           0.99\n",
      "\n",
      "\u001b[1;31mRecall Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.79           0.94           0.93\n",
      "TFIDF                0.67           0.94           0.92\n",
      "Word2Vec             0.67           0.94           0.92\n",
      "\n",
      "\u001b[1;31mF1 Score Metrix\n",
      "\u001b[0m\n",
      "              Naive Bayes  Decision Tree  Random Forest\n",
      "Bag-of-words         0.87           0.93           0.96\n",
      "TFIDF                0.80           0.93           0.96\n",
      "Word2Vec             0.80           0.93           0.96\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary that stores all the accuracy information\n",
    "performance_dict = {}\n",
    "\n",
    "for me in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "    performance_dict[me] = {}\n",
    "    for m in [\"mnb\",\"dt\",\"rf\"]:\n",
    "        performance_dict[me][m] = {}\n",
    "        for f in [\"bow\",\"tfidf\",\"avgwv\"]:\n",
    "            exec('performance_dict[\"{}\"][\"{}\"][\"{}\"] = {}_{}_metrics[\"{}\"]'.format(me, m, f, m, f, me))\n",
    "        \n",
    "#Accuracy Matrix\n",
    "print(\"\\n\\033[1;31mAccuracy Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"accuracy\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#Precision Matrix\n",
    "print(\"\\n\\033[1;31mPrecision Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"precision\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#Recall Matrix\n",
    "print(\"\\n\\033[1;31mRecall Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"recall\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#F1 Score Matrix\n",
    "print(\"\\n\\033[1;31mF1 Score Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"f1\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Feedforward Neural Network Classifier through PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.8.1-cp38-none-macosx_10_9_x86_64.whl (119.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 119.6 MB 39.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/nicolasclarke/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /Users/nicolasclarke/opt/anaconda3/lib/python3.8/site-packages (from torch) (1.19.2)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction—forward—from the input nodes, through the hidden nodes (if any), and to the output nodes. There are no cycles or loops in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, init_in_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(init_in_features, 100)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "        self.linear3 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "def Neural_Network_Classify(x_train, y_train, x_test, y_test, init_in_features):\n",
    "    model = LogisticRegression(init_in_features = init_in_features)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)\n",
    "    \n",
    "    if not isinstance(x_train, np.ndarray):\n",
    "        x_train = x_train.toarray()\n",
    "        x_test = x_test.toarray()\n",
    "    x_train = Variable(torch.from_numpy(x_train)).float()\n",
    "    y_train = Variable(torch.from_numpy(y_train.values)).long()\n",
    "\n",
    "    epochs = 20\n",
    "    model.train()\n",
    "    loss_values = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss_values.append(loss.item())\n",
    "        pred = torch.max(y_pred, 1)[1].eq(y_train).sum()\n",
    "        acc = pred * 100.0 / len(x_train)\n",
    "        print('Epoch: {}, Loss: {}, Accuracy: {}%'.format(epoch+1, loss.item(), acc.numpy()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    plt.plot(loss_values)\n",
    "    plt.title('Loss Value vs Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Loss'])\n",
    "    plt.show()\n",
    "\n",
    "    x_test = Variable(torch.from_numpy(x_test)).float()\n",
    "    y_test = Variable(torch.from_numpy(y_test.values)).long()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_test)\n",
    "        loss = criterion(y_pred, y_test)\n",
    "        pred = torch.max(y_pred, 1)[1].eq(y_test).sum()\n",
    "        accuracy_nn = float(pred/len(x_test))\n",
    "        print (\"Accuracy : {}%\".format(100*accuracy_nn))\n",
    "\n",
    "    return get_metrics(true_labels=y_test, predicted_labels=np.argmax(y_pred, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7158291339874268, Accuracy: 32.906089782714844%\n",
      "Epoch: 2, Loss: 0.671406626701355, Accuracy: 32.93073654174805%\n",
      "Epoch: 3, Loss: 0.676488995552063, Accuracy: 33.1525764465332%\n",
      "Epoch: 4, Loss: 0.4886412024497986, Accuracy: 86.2459945678711%\n",
      "Epoch: 5, Loss: 0.38467419147491455, Accuracy: 97.461181640625%\n",
      "Epoch: 6, Loss: 0.2838684916496277, Accuracy: 98.24993896484375%\n",
      "Epoch: 7, Loss: 0.19795532524585724, Accuracy: 99.16194152832031%\n",
      "Epoch: 8, Loss: 0.13389693200588226, Accuracy: 99.3098373413086%\n",
      "Epoch: 9, Loss: 0.09154841303825378, Accuracy: 99.359130859375%\n",
      "Epoch: 10, Loss: 0.06460966169834137, Accuracy: 99.53167724609375%\n",
      "Epoch: 11, Loss: 0.04623182862997055, Accuracy: 99.6795654296875%\n",
      "Epoch: 12, Loss: 0.032156988978385925, Accuracy: 99.82746124267578%\n",
      "Epoch: 13, Loss: 0.019609171897172928, Accuracy: 99.90140533447266%\n",
      "Epoch: 14, Loss: 0.013455565087497234, Accuracy: 99.92605590820312%\n",
      "Epoch: 15, Loss: 0.009882114827632904, Accuracy: 99.92605590820312%\n",
      "Epoch: 16, Loss: 0.03599846363067627, Accuracy: 99.87675476074219%\n",
      "Epoch: 17, Loss: 0.004611391574144363, Accuracy: 99.95069885253906%\n",
      "Epoch: 18, Loss: 0.0032471450977027416, Accuracy: 99.95069885253906%\n",
      "Epoch: 19, Loss: 0.0024212957359850407, Accuracy: 99.95069885253906%\n",
      "Epoch: 20, Loss: 0.0019167423015460372, Accuracy: 99.95069885253906%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAunElEQVR4nO3deXxcZdn/8c+VvUvSJUnTJd3pFqALhJa1ZStLQSsuUERRXLA+IiKo4IbyoD4gogjUH6KyCEJVVKxQLKttka0tttgVShearumSpmmaZrt+f8wJDCFp0zYnZ5L5vl+veWXOOffMXHM6ne+c+5xzH3N3REQkeaVEXYCIiERLQSAikuQUBCIiSU5BICKS5BQEIiJJTkEgIpLkFAQigJn9y8y+EHUdicLMTjezkqjrkLahIJBWZ2brzOzsNn7Nb5vZvCbm55lZtZkd05b1tCYzG2RmbmYVjW6XRF2bdAxpURcg0koeAm42s8HuvjZu/jTgv+6+NKK6WlN3d6+NugjpeLRFIG3GzDLN7A4z2xTc7jCzzGBZnpk9YWZlZrbTzOabWUqw7Hoz22hme8xslZmd1fi53b0EeB74dKNFlwMPmlmP4PlLzWxXcL+wmTp/aGYPx003/CJPC6a7mdnvzGxzUNePzCy1iefpa2b7zKxn3LxxZrbdzNLN7Cgzm2tmu4N5fzz0tQpm9oCZ3WNmzwTraK6ZDYxbfrKZLQheZ4GZnRy3rKeZ3R/8e+wys8cbPfd1ZrYteK9XxM2fYmbLg9fbaGbfOJzaJTEoCKQtfRc4ERgLjAHGA98Lll0HlAD5QAHwHcDNbARwFXCCu2cD5wLrmnn+B4kLguCxY4FHiX3W7wcGAgOAfcDdh/k+HgRqgaOAccA5wAf2L7j7JuBl4GNxsz8JPObuNcDNwNNAD6AQuOsw6wG4LHi+PGAx8AeIfdEDTwJ3ArnAz4EnzSw3eNxDQGfgaKAX8Iu45+wNdAP6AZ8HZphZj2DZ74AvBf8mxxALYWmnFATSli4D/tfdt7l7KXAT731x1wB9gIHuXuPu8z02EFYdkAkUmVm6u69z97ebef6/AQVxv3gvB55y91J33+Huf3H3SnffA/wYmHSob8DMCoDzgWvcfa+7byP25TmtmYc8AlwaPNaCdo/EveeBQF93r3L3Fw/y8tuDLaaG26i4ZU+6+zx3308scE8ys/7ABcBb7v6Qu9e6+6PASuBDZtYneC/T3X1XsN7nxj1nDbF/rxp3nw1UACPilhWZWU7w2NcPUrskMAWBtKW+wPq46fXBPIDbgNXA02a2xsxuAHD31cA1wA+BbWY208z60gR3rwT+DFwefOleRuzXO2bW2cx+bWbrzawcmAd0b6pL5yAGAunA5oYvZODXxH5NN+UxYl/KfYGJgAPzg2XfAgx4zcyWmdnnDvLaee7ePe62Im7ZhoY77l4B7CS2bhuvc4LpfkB/YKe772rm9XY02idRCXQN7n8MmAKsD7qiTjpI7ZLAFATSljYR+yJtMCCYh7vvcffr3H0I8CHg2oZ9Ae7+iLufGjzWgVsP8BoPAhcDk4Fs4Ilg/nXEfs1OcPccYl/KEPsibmwvse6SBr3j7m8A9vP+L+Ucdz+6qWLcvYxY98/FxLqFHg22dHD3Le7+RXfvC3wJ+JWZHXWA93Yg/RvumFlXoCexddt4nUNsvW8M3ktPM+t+qC/m7gvcfSqxAHwc+NNhVS0JQUEgYUk3s6y4WxqxvvrvmVm+meUBNwIPA5jZhcHOUwPKiXUJ1ZnZCDM7M9ipXEWsb7/uAK87HygD7gVmunt1MD87eGxZ0G/+gwM8x2JgopkNMLNuwLcbFrj7ZmJf7LebWY6ZpZjZUDM7UDfTI8S6qT7Ge91CmNkn4nZY7yIWcgd6bwcyxcxONbMMYvsKXnX3DcBsYLiZfdLM0ix2yGkR8ETwXp4iFkA9gh3YE5t/iXfrzjCzy8ysW7Cvo+HfS9opBYGEZTaxL96G2w+BHwELgTeA/wKvB/MAhgHPEuuHfhn4lbv/i9j+gVuA7cAWYr9Av9Pciwa/tn9P7Ffw7+MW3QF0Cp7nFeCfB3iOZ4A/BnUu4r2tigaXAxnAcmJf4I8R27/RnFnB+9vq7kvi5p8AvGpmFUGbrzU69LWxMnv/eQTXxi17hFi47QSOJ9YthrvvAC4ktkW0g1h31IXuvj143KeJ9fevBLYR64ZriU8D64JutunAp1r4OElApgvTiLRvZvYAUOLu3ztYW5GmaItARCTJKQhERJKcuoZERJKctghERJJcuxt0Li8vzwcNGhR1GSIi7cqiRYu2u3t+U8vaXRAMGjSIhQsXRl2GiEi7YmaNzzB/l7qGRESSnIJARCTJKQhERJJcu9tHICJyuGpqaigpKaGqqirqUkKTlZVFYWEh6enpLX6MgkBEkkZJSQnZ2dkMGjSI2PiGHYu7s2PHDkpKShg8eHCLH6euIRFJGlVVVeTm5nbIEAAwM3Jzcw95i0dBICJJpaOGQIPDeX9JEwQ791Zz0z+WUVlde/DGIiJJJGmC4N+rt/PAS+uYeve/Wb2tIupyRCRJde3a9eCN2lioQWBm55nZKjNb3XAN2kbLv2lmi4PbUjOrC64e1eo+NKYvD31uAjv2VvPhu1/kH0s2hfEyIiLtTmhBEFwUfAZwPrFL411qZkXxbdz9Nncf6+5jiV0OcK677wyrplOH5fHk1acyqk8OX330P/xw1jKqa+vDejkRkRZZvHgxJ554IqNHj+aiiy5i165dANx5550UFRUxevRopk2bBsDcuXMZO3YsY8eOZdy4cezZs+eIXz/Mw0fHA6vdfQ2Amc0EphK7vF9TLiV2TdtQ9enWiZlXnsgtT63kdy+uZfGGMmZcdhz9uncK+6VFJIHc9I9lLN9U3qrPWdQ3hx986OhDftzll1/OXXfdxaRJk7jxxhu56aabuOOOO7jllltYu3YtmZmZlJWVAfCzn/2MGTNmcMopp1BRUUFWVtYR1x1m11A/YEPcdEkw7wPMrDNwHvCXEOt5V3pqCt+/sIhfXXYcq7dVcOGd85n7ZmlbvLSIyPvs3r2bsrIyJk2aBMBnPvMZ5s2bB8Do0aO57LLLePjhh0lLi/1uP+WUU7j22mu58847KSsre3f+kQhzi6CpY5iauwrOh4B/N9ctZGZXAlcCDBgwoHWqA6Yc24eRvbP5nz+8zmfvf42rzxzG1WcNIzWlYx9eJiIc1i/3tvbkk08yb948Zs2axc0338yyZcu44YYbuOCCC5g9ezYnnngizz77LCNHjjyi1wlzi6AE6B83XQg0t4d2GgfoFnL3e9292N2L8/ObHE77sA3J78rf/ucULhrXj18+9xafvf81du6tbtXXEBFpTrdu3ejRowfz588H4KGHHmLSpEnU19ezYcMGzjjjDH76059SVlZGRUUFb7/9NsceeyzXX389xcXFrFy58ohrCHOLYAEwzMwGAxuJfdl/snEjM+sGTAI+FWItB9QpI5XbPzGGEwb15AezlnHBnfOZcdlxHDegR1QliUgHVVlZSWFh4bvT1157LQ8++CDTp0+nsrKSIUOGcP/991NXV8enPvUpdu/ejbvz9a9/ne7du/P973+fF154gdTUVIqKijj//POPuKbQgsDda83sKmAOkArc5+7LzGx6sPyeoOlFwNPuvjesWlrCzLh0/ACO7deNL/9hERff8zLfvWAUnz25Y45JIiLRqK9v+kjFV1555QPzXnzxxQ/Mu+uuu1q9plAHnXP32cDsRvPuaTT9APBAmHUcimP6deOJq07juj8v5qZ/LGfh+l3c+rHRdM3U+Hwi0jHp260J3Tqnc++ni/n1vDXcNmclKzaXc8+njmd4QfZBH1tbV8/OvdVsr6hmx979bK/Yz46Kakor9lNX51x3zgg6ZaS2wbsQEWkZBUEzUlKML58+lLH9u/PVR//D1Lv/zXcvGEVBTlbw5b6f7RXVbK9478t+e8V+dlXWNPl8aSlGbb1zbGE3po5t8ihaEWkD7t6hu3vdmzs4s3kKgoM4aWgus68+lase/Q/fe3zp+5ZlZ6WR3zWT3K4ZDM3vyoQhPcntkklediZ5XTLIy84kt0sGuV0z6ZqZxoSfPMfTy7cqCEQikpWVxY4dOzrsUNQN1yM41JPMFAQt0Csni0e+MIFF63fROSON3K4Z5HbNIDPt0Lp4zh7Viyfe2Mz+2rpDfqyIHLnCwkJKSkooLe24J5A2XKHsUCgIWigtNYUJQ3KP6DkmFxUwc8EGXlmzk0nDW/d8CBE5uPT09EO6cleySJphqBPBKUfl0Sk9lWeXb426FBGRdykI2lBWeioTh+fx7Iqth7VDR0QkDAqCNja5qDebd1exdGPrjnooInK4FARt7MyRvUgxeGb5lqhLEREBFARtrmeXDIoH9uRp7ScQkQShIIjA5KICVm7Zw4adlVGXIiKiIIjC5KICAJ7RVoGIJAAFQQQG5XVhWK+uPLtCQSAi0VMQRGRyUQGvrt3J7mbGJhIRaSsKgohMLiqgrt55YdW2qEsRkSSnIIjImMLu5Gdnaj+BiEROQRCRlBTj7FG9+NeqbeyvrYu6HBFJYgqCCE0uKmBvdR0vv70j6lJEJIkpCCJ08tA8Omek6ughEYlUqEFgZueZ2SozW21mNzTT5nQzW2xmy8xsbpj1JJqs9FQmDsvn2eXbNAidiEQmtCAws1RgBnA+UARcamZFjdp0B34FfNjdjwY+EVY9iWpyUQFbyqv478bdUZciIkkqzC2C8cBqd1/j7tXATGBqozafBP7q7u8AuHvSHUt5xruD0Kl7SESiEWYQ9AM2xE2XBPPiDQd6mNm/zGyRmV3e1BOZ2ZVmttDMFna0S8z17JJB8aCeCgIRiUyYQdDUlaEbd4SnAccDFwDnAt83s+EfeJD7ve5e7O7F+fkd7xKP52gQOhGJUJhBUAL0j5suBDY10eaf7r7X3bcD84AxIdaUkBoGodPQ1CIShTCDYAEwzMwGm1kGMA2Y1ajN34HTzCzNzDoDE4AVIdaUkAbmdmF4QVddy1hEIhFaELh7LXAVMIfYl/uf3H2ZmU03s+lBmxXAP4E3gNeA37r70rBqSmSTiwp4bd1Oyiqroy5FRJJMqOcRuPtsdx/u7kPd/cfBvHvc/Z64Nre5e5G7H+Pud4RZTyI7e5QGoRORaOjM4gQxprA7vTQInYhEQEGQIFJSjLNGFTB3VakGoRORNqUgSCDnBIPQvaRB6ESkDSkIEshJQ3Njg9Cpe0hE2pCCIIFkpacyaXg+z67YSn29BqETkbahIEgwZ48qYGv5fg1CJyJtRkGQYM4c2YvUFNPRQyLSZhQECaZHlwyKB/ZQEIhIm1EQJKDJRQWs2rqHd3ZoEDoRCZ+CIAGdU9QbgKeXb4m4EhFJBgqCBDQgtzMjCrJ1LWMRaRMKggR1dlEvFqzbpUHoRCR0CoIENbmoN3X1zvMrNQidiIRLQZCgRvfrpkHoRKRNKAgSVEqKcXZRAXPfLKWqRoPQiUh4FAQJbHJRAZXVdbysQehEJEQKggR28tBcumSk8oyOHhKRECkIElhmWiqTRuTz7HINQici4VEQJLizRxWwbc9+3tAgdCISklCDwMzOM7NVZrbazG5oYvnpZrbbzBYHtxvDrKc9em8QOp1lLCLhCC0IzCwVmAGcDxQBl5pZURNN57v72OD2v2HV015175zBCYM0CJ2IhCfMLYLxwGp3X+Pu1cBMYGqIr9dhTS7qzZtbK1i/Y2/UpYhIBxRmEPQDNsRNlwTzGjvJzJaY2VNmdnRTT2RmV5rZQjNbWFpaGkatCe2cogIAbRWISCjCDAJrYl7jQ19eBwa6+xjgLuDxpp7I3e9192J3L87Pz2/dKtuB/j07M7J3toJAREIRZhCUAP3jpguBTfEN3L3c3SuC+7OBdDPLC7GmduvsUQUsWLeTnXs1CJ2ItK4wg2ABMMzMBptZBjANmBXfwMx6m5kF98cH9eg02iZ8aExf6h1+M39N1KWISAcTWhC4ey1wFTAHWAH8yd2Xmdl0M5seNPs4sNTMlgB3AtPcXWdONWFE72w+Oq4fv3txLSW7dOUyEWk91t6+d4uLi33hwoVRlxGJTWX7OONn/+L8Y3pzx7RxUZcjIu2ImS1y9+KmlunM4nakb/dOfOG0wTy+eBNLNpRFXY6IdBAKgnZm+qSh5HXN4MezV9DetuZEJDEpCNqZ7Kx0rjl7OK+t3anDSUWkVSgI2qFpJ/TnqF5dueWpldTU1Uddjoi0cwqCdigtNYXvTBnJmu17eeTVd6IuR0TaOQVBO3XGiF6cPDSXO559k937aqIuR0TaMQVBO2VmfGfKKMr21fCrf62OuhwRaccUBO3YMf268dFxhdz/4jo27NRJZiJyeBQE7dw3zh1OSgrcNmdV1KWISDulIGjn+nTrxBdPG8KsJZtYrJPMROQwKAg6gC9NGkpe10x+/ORynWQmIodMQdABdM1M49rJw1mwbhdzlunaxiJyaBQEHcTFxYUMC04yq67VSWYi0nIKgg4iLTWF71wwinU7Knn4lfVRlyMi7YiCoAM5fXg+px6Vx53Pv8XuSp1kJiItoyDoQBpOMtu9r4a7X3gr6nJEpJ1QEHQwRX1z+PhxhTz40nre2aGTzETk4BQEHdB154wgNcW4dc7KqEsRkXZAQdAB9e6WxRcnDuHJNzazaP2uqMsRkQQXahCY2XlmtsrMVpvZDQdod4KZ1ZnZx8OsJ5l8aeIQ8rMz+YmuZCYiBxFaEJhZKjADOB8oAi41s6Jm2t0KzAmrlmTUJTON6yYPZ9H6XTy1VCeZiUjzwtwiGA+sdvc17l4NzASmNtHuq8BfgG0h1pKUPlHcnxEF2TrJTEQOKMwg6AdsiJsuCea9y8z6ARcB9xzoiczsSjNbaGYLS0tLW73Qjio1xfj2lJG8s7OS37+8LupyRCRBhRkE1sS8xp3VdwDXu3vdgZ7I3e9192J3L87Pz2+t+pLC6SN6cdqwPO56fjVlldVRlyMiCSjMICgB+sdNFwKbGrUpBmaa2Trg48CvzOwjIdaUlL4zZRTlVTXc9byuZCYiH9SiIDCzLmaWEtwfbmYfNrP0gzxsATDMzAabWQYwDZgV38DdB7v7IHcfBDwG/I+7P36ob0IObFSfHC4+vj+/f3kd67bvjbocEUkwLd0imAdkBX36zwFXAA8c6AHuXgtcRexooBXAn9x9mZlNN7Pph1+yHI7rzhlOemoKP5m9IupSRCTBpLWwnbl7pZl9HrjL3X9qZv852IPcfTYwu9G8JncMu/tnW1iLHIZeOVl85YyjuG3OKl5avZ2Tj8qLuiQRSRAt3SIwMzsJuAx4MpjX0hCRBPH5UwfTr3sn/veJ5dTW6XBSEYlpaRBcA3wb+FvQvTMEeCG0qiQUWempfGfKKFZu2cPMBRsO/gARSQotCgJ3n+vuH3b3W4Odxtvd/eqQa5MQTDm2N+MH9eTnz7zJ7n26ZoGItPyooUfMLMfMugDLgVVm9s1wS5MwmBk3fqiIXZXV3PmcrlkgIi3vGipy93LgI8R2/g4APh1WURKuY/p14+Lj+/PgS+t4u7Qi6nJEJGItDYL04LyBjwB/d/caPniWsLQj3zh3BFnpqfz4SR1OKpLsWhoEvwbWAV2AeWY2ECgPqygJX352JledeRTPr9zG3Dc1fpNIMmvpzuI73b2fu0/xmPXAGSHXJiG74pRBDMztzM1PLKdGh5OKJK2W7izuZmY/bxgB1MxuJ7Z1IO1YZlrscNLV2yr4wyvroy5HRCLS0q6h+4A9wMXBrRy4P6yipO2cU1TAyUNz+cWzb2l0UpEk1dIgGOruPwguMrPG3W8ChoRZmLSNhsNJ91TVcMezOpxUJBm1NAj2mdmpDRNmdgqwL5ySpK2N7J3DpeMH8NAr63lr656oyxGRNtbSIJgOzDCzdcG1A+4GvhRaVdLmrp08nM4Zqdz8pC52L5JsWnrU0BJ3HwOMBka7+zjgzFArkzaV2zWTr501jHlvlvLCKl0+WiSZHNIVyty9PDjDGODaEOqRCF1+0iCG5HXhR0+s0MXuRZLIkVyqsqlrEks7lpGWwncvGMWa7Xt1sXuRJHIkQaCO5A7ozJGxi93/8rm32FGxP+pyRKQNHDAIzGyPmZU3cdsD9G2jGqUNmRk3XlhEZXUdP3/mzajLEZE2cMAgcPdsd89p4pbt7ge9QpmZnWdmq8xstZnd0MTyqWb2hpktDs5YPrWp55G2Nawgm09NGMCjr73Dis0aUkqkozuSrqEDMrNUYAZwPlAEXGpmRY2aPQeMcfexwOeA34ZVjxyaa84eTnZWOjc/sVyHk4p0cKEFATAeWB2ciVwNzASmxjdw9wp/71umC9rvkDB6dMng62cP46W3d/D08q1RlyMiIQozCPoB8RfGLQnmvY+ZXWRmK4EniW0VfICZXdkw4F1pqYZMbiuXnTiQo3p15SezV7C/ti7qckQkJGEGQVOHl37gF7+7/83dRxK76M3NTT2Ru9/r7sXuXpyfn9+6VUqz0lNT+P6FRazfUcn9/14XdTkiEpIwg6AE6B83XQhsaq6xu88DhppZXog1ySGaNDyfM0f24u7nV1O6R4eTinREYQbBAmCYmQ02swxgGjArvoGZHWVmFtw/DsgAdoRYkxyG714wiqqaOm5/elXUpYhICEILAnevBa4C5gArgD+5+zIzm25m04NmHwOWmtliYkcYXeI6RCXhDM3vyuUnDeKPCzewZENZ1OWISCuz9va9W1xc7AsXLoy6jKSze18N5/xiLjlZ6fzjq6eSlZ4adUkicgjMbJG7Fze1LMyuIelAunVK55aPjeatbRW6gI1IB6MgkBY7Y0QvLinuz73z3ub1d3ZFXY6ItBIFgRyS7144it45WXzjT0uoqtG5BSIdgYJADklOVjo//fgY1mzfy8/m6CgikY5AQSCH7NRheVw2YQC/+/daXlu7M+pyROQIKQjksHxnyij6de/ENx9bQmV1bdTliMgRUBDIYemSmcZtHx/D+h2V/PSf6iISac8UBHLYThqay2dPHsQDL63jpbe3R12OiBwmBYEckW+dN4JBuZ351mNvULFfXUQi7ZGCQI5I54w0fvaJMWws28f/zV4RdTkichgUBHLEigf15AunDuYPr77D/Ld0vQiR9kZBIK3iunNGMCS/C9c/9gblVTVRlyMih0BBIK0iKz2V2z8xhi3lVfzoieVRlyMih0BBIK1m3IAefGnSUP60sIQXVm6LuhwRaSEFgbSqa84exvCCrtzw1zfYXakuIpH2QEEgrSozLZXbPzGW7RXV3PSPZVGXIyItoCCQVndsYTe+cvpQ/vqfjTy9bEvU5YjIQSgIJBRXnTmMUX1y+M7flrJrb3XU5YjIASgIJBQZaSnc/okxlFVWc+MsdRGJJLJQg8DMzjOzVWa22sxuaGL5ZWb2RnB7yczGhFmPtK2ivjlcfdYw/rFkE7P/uznqckSkGaEFgZmlAjOA84Ei4FIzK2rUbC0wyd1HAzcD94ZVj0Tjy6cP5dh+3fje40vZXrE/6nJEpAlhbhGMB1a7+xp3rwZmAlPjG7j7S+7ecPHbV4DCEOuRCKSnpnD7xWOoqKrl+48vxd2jLklEGgkzCPoBG+KmS4J5zfk88FRTC8zsSjNbaGYLS0s1lk17M7wgm69PHs5TS7fw4Evroi5HRBoJMwisiXlN/hw0szOIBcH1TS1393vdvdjdi/Pz81uxRGkrV04cwjlFBdz0xHKeeGNT1OWISJwwg6AE6B83XQh84BvAzEYDvwWmuvuOEOuRCKWmGHdeOo7igT249o9LdCEbkQQSZhAsAIaZ2WAzywCmAbPiG5jZAOCvwKfd/c0Qa5EEkJWeym8vP4FBeZ258veLWLpxd9QliQghBoG71wJXAXOAFcCf3H2ZmU03s+lBsxuBXOBXZrbYzBaGVY8khm6d03nwc+PJyUrjs/cv4J0dlVGXJJL0rL0dxVFcXOwLFyov2rvV2/bw8XtepnundB778snkdc2MuiSRDs3MFrl7cVPLdGaxROKoXtn87jMnsKW8is89sIC9ut6xSGQUBBKZ4wf2YMYnj2PZpnKmP7yI6tr6qEsSSUoKAonUWaMK+L+PHsv8t7bzzceWUF/fvroqRTqCtKgLELm4uD+le/Zz25xV5HfN5HsXNh6JRETCpCCQhPA/pw+ldM9+fvviWnrlZHLlxKFRlySSNBQEkhDMjBsvLKK0Yj8/mb2SvK6ZfPQ4DT0l0hYUBJIwUlKMn188hl17q/nWY2/Qs0sGp4/oFXVZIh2edhZLQslMS+XXnz6e4QXZfPnh11m8oSzqkkQ6PAWBJJzsrHQe+NwJ5GVn8LkHFrCmtCLqkkQ6NAWBJKRe2Vk89LkJGHD5fa+xrbwq6pJEOiwFgSSsQXlduP+KE9i5t5rL73uN8qqaqEsS6ZAUBJLQRhd2555PHc/qbRV88cGF7Kuui7okkQ5HQSAJb+LwfG6/eAyvrdvJ1BkvsmrLnqhLEulQFATSLkwd248HrxjPzr3VfPjuF/nDq+t1/WORVqIgkHZj4vB8nvraRMYP7sl3/7aUrzzyOrv3ab+ByJFSEEi7kp+dyYNXjOeG80fy9LKtTPnlfBat3xV1WSLtmoJA2p2UFGP6pKH8efpJpKTAxb9+mRkvrNbIpSKHSUEg7da4AT148urTOP+Y3tw2ZxWfvu9VnW8gchgUBNKu5WSlc9el47j1Y8eyaP0uzv/lfP61alvUZYm0K6EGgZmdZ2arzGy1md3QxPKRZvayme03s2+EWYt0XGbGJScM4B9XnUp+diafvX8BP5m9Qlc8E2mh0ILAzFKBGcD5QBFwqZk1vuLITuBq4Gdh1SHJY1hBNo9/5RQ+feJA7p23hk/c8xLrd+yNuiyRhBfmFsF4YLW7r3H3amAmMDW+gbtvc/cFgI4BlFaRlZ7KzR85hns+dRxrt+/lgjtf5O+LN0ZdlkhCCzMI+gEb4qZLgnmHzMyuNLOFZrawtLS0VYqTju28Y/ow+2unMbJ3Nl+buZhv/nkJldW1UZclkpDCDAJrYt5hHd/n7ve6e7G7F+fn5x9hWZIsCnt0ZuaVJ/LVM4/isddLuPCuF3luxVYdZirSSJhBUAL0j5suBDaF+HoiH5CWmsJ154zgD1+YQHVtPZ9/cCHn/XIef1lUQk2ddiaLQLhBsAAYZmaDzSwDmAbMCvH1RJp18tA8XvjG6fzikjGkmHHdn5cw6acv8LsX17J3v7qMJLlZmAN3mdkU4A4gFbjP3X9sZtMB3P0eM+sNLARygHqgAihy9/LmnrO4uNgXLlwYWs3S8bk7/1pVyv+b+zavrd1J987pXH7SID578iB6dsmIujyRUJjZIncvbnJZexvBUUEgrWnR+l3cM/dtnlm+laz0FC4p7s8XThtC/56doy5NpFUpCEQOYvW2Pfx67hoeX7yReocLR/dh+qShjOqTE3VpIq1CQSDSQpt37+N389fy6GvvsLe6jtNH5DN90lAmDO6JWVMHwom0DwoCkUO0u7KGh15Zx/3/XseOvdWM7d+d6ZOGctaoXqSnaoguaX8UBCKHqaqmjj8v3MC989ewYec+unVK56xRvTjv6N5MHJ5PVnpq1CWKtIiCQOQI1dbV8/zKbfxz6RaeXbGV8qpaOqWnMml4Pucd05szRvaiW6f0qMsUadaBgiCtrYsRaY/SUlM45+jenHN0b2rq6nllzQ7mLNvC08u28s9lW0hLMU4amst5x/RmclEBvbKzoi5ZpMW0RSByBOrrnf9sKOPpZVuYs2wL63ZUYgbHDejBuUcXcO7RvRmY2yXqMkXUNSTSFtydVVv3MGfpVuYs28LyzbHzIkf2zubco3tz7tG9GdUnW0cfSSQUBCIR2LCzkjnBlsLC9btwh7yuGYwf3JPxg3oyfnAuI3tnk5KiYJDwKQhEIla6Zz/Pr9zKq2t28uranWws2wdATlZaLBgG92TC4FyO7ptDmg5PlRAoCEQSTMmuSl5bu/Pd25rtsSupdclI5biBPZgwuCcThuQyurAbmWk6RNXdWb2tgn49OtE5Q8e4HA4dNSSSYAp7dKawR2c+elwhANvKq3ht3XvB8LOn3wQgIy2Fcf27M2FILhMG92RM/+50zUye/7Y1dfXM/u9mfjN/DUs3lpOfnck1Zw/jkuL+2nJqRdoiEElAu/ZWsyAIhlfX7mTZpt3UO6QYDC/IZmz/7owb0J1xA3owNL8rqR1sP8Oeqhr+uGAD9724lk27qxiS34VLTxjw7v6WIfld+Na5Izn36ALtfG8hdQ2JtHN7qmpYtH4XizeU8Z93yli8oYzd+2KX+u6amcaY/t1i4dC/B2MHdCeva2bEFR+eTWX7uP/fa5n52gb27K9lwuCeXDlxCGeM6EVKiuHuPLN8K7f+cyVvl+7l+IE9+Pb5Iyke1DPq0hOegkCkg3F31m7f+24o/GfDLlZu3kNtcBnO/j07xUIh2HIo6puT0Psalm7czW/mr+HJNzbjwJRj+/DF0wYzurB7k+1r6+p5bFEJv3j2TbaW72dyUQHXnzeCo3plt2nd7YmCQCQJ7KuuY+mm3Sx+JxYMi98pY9PuKgAyUlMY1TeHgT0707tbFgU5WfQJ/vbulkWv7Mw2H0yvvt6Z+2Yp985bw8trdtAlI5Vp4wdwxSmDKOzRsutB7Kuu475/r+Wef73N3upaLjmhP9ecPZyCHJ3Z3ZiCQCRJbS2v4j9BMPy3ZDcby/axZXcV+2vff71mM8jtkhkXDpn0znkvKBrmd81MO+I++aqaOv6+eCO/mb+W1dsq6J2TxRWnDGLa+AGHPV7Tzr3V3PX8Wzz8ynpSU4zPnzqYL00aSk6Wxn9qoCAQkXe5O2WVNWwpr4rddsduW+Ony6soq6z5wGPTUozsrDRyOqWTk5VOTqc0crLSY/Oy0oP5seXZWe/dz+mUTorBYwtLePDldWyvqKaoTw5fnDiYC47tS0Za62yNvLOjktufWcXfF2+iR+d0vnrmMC47cUBCd4u1lciCwMzOA35J7JrFv3X3Wxott2D5FKAS+Ky7v36g51QQiLSNqpo6tpZXsbkhJHZXsXtfDeVVNeypqqV8Xw3l7/6toXxfLftq6g76vJOG53PlxCGcPDQ3tCN+lm7czS1PreTF1dvp37MT3zhnBB8a3Tepz+KOJAjMLBV4E5gMlAALgEvdfXlcmynAV4kFwQTgl+4+4UDPqyAQSVw1dfVxIRELh9jfGvZW13HqUXmM6N12O3TnvVnKLU+tZPnmco7pl8MJg3qSkZpCesMtzd4/nWpkpDWaTk0hPZiXlmKkxt0+OJ1CqhmpqbFlKRb8TYAAiuqEsvHAandfExQxE5gKLI9rMxX4vcfS6BUz625mfdx9c4h1iUhI0lNT6Nklg55dMqIuBYCJw/M59ag8/r5kIzNeeJvHFpVQU1dPTZ1TV9923eJmkGqxQEgxSDEj1QwzgnnvzW+4b2akpASPC9peOn4AXzhtSKvXF2YQ9AM2xE2XEPvVf7A2/YD3BYGZXQlcCTBgwIBWL1REOq6UFOOicYVcNK7wffPr6j0IhVgw1NTVU13baLqunpra2HR1XR119VBXX09tfSxI6ur9ffcbpuvfnV//vsfUe2wfTV1wv94d99j9uob79bH5senY/Ya2+dnhnB8SZhA0tS3UOIJb0gZ3vxe4F2JdQ0demogku1h3TqouNwqEeeBwCdA/broQ2HQYbUREJERhBsECYJiZDTazDGAaMKtRm1nA5RZzIrBb+wdERNpWaF1D7l5rZlcBc4gdPnqfuy8zs+nB8nuA2cSOGFpN7PDRK8KqR0REmhbqeLbuPpvYl338vHvi7jvwlTBrEBGRA9OA3iIiSU5BICKS5BQEIiJJTkEgIpLk2t3oo2ZWCqw/zIfnAdtbsZzWluj1QeLXqPqOjOo7Molc30B3z29qQbsLgiNhZgubG3QpESR6fZD4Naq+I6P6jkyi19ccdQ2JiCQ5BYGISJJLtiC4N+oCDiLR64PEr1H1HRnVd2QSvb4mJdU+AhER+aBk2yIQEZFGFAQiIkmuQwaBmZ1nZqvMbLWZ3dDEcjOzO4Plb5jZcW1YW38ze8HMVpjZMjP7WhNtTjez3Wa2OLjd2Fb1Ba+/zsz+G7z2By4QHfH6GxG3XhabWbmZXdOoTZuvPzO7z8y2mdnSuHk9zewZM3sr+Nujmcce8PMaYn23mdnK4N/wb2bWvZnHHvDzEGJ9PzSzjXH/jlOaeWxU6++PcbWtM7PFzTw29PV3xDy4PFpHuREb8vptYAiQASwBihq1mQI8RewKaScCr7ZhfX2A44L72cCbTdR3OvBEhOtwHZB3gOWRrb8m/q23EDtRJtL1B0wEjgOWxs37KXBDcP8G4NZm3sMBP68h1ncOkBbcv7Wp+lryeQixvh8C32jBZyCS9ddo+e3AjVGtvyO9dcQtgvHAandf4+7VwExgaqM2U4Hfe8wrQHcz69MWxbn7Znd/Pbi/B1hB7DrN7Ulk66+Rs4C33f1wzzRvNe4+D9jZaPZU4MHg/oPAR5p4aEs+r6HU5+5Pu3ttMPkKsSsERqKZ9dcSka2/BmZmwMXAo639um2lIwZBP2BD3HQJH/yibUmb0JnZIGAc8GoTi08ysyVm9pSZHd22leHA02a2yMyubGJ5Qqw/Yle9a+4/X5Trr0GBB1fcC/72aqJNoqzLzxHbymvKwT4PYboq6Lq6r5mutURYf6cBW939rWaWR7n+WqQjBoE1Ma/xMbItaRMqM+sK/AW4xt3LGy1+nVh3xxjgLuDxtqwNOMXdjwPOB75iZhMbLU+E9ZcBfBj4cxOLo15/hyIR1uV3gVrgD800OdjnISz/DxgKjAU2E+t+aSzy9QdcyoG3BqJafy3WEYOgBOgfN10IbDqMNqExs3RiIfAHd/9r4+XuXu7uFcH92UC6meW1VX3uvin4uw34G7HN73iRrr/A+cDr7r618YKo11+crQ1dZsHfbU20ifqz+BngQuAyDzq0G2vB5yEU7r7V3evcvR74TTOvG/X6SwM+CvyxuTZRrb9D0RGDYAEwzMwGB78apwGzGrWZBVweHP1yIrC7YRM+bEF/4u+AFe7+82ba9A7aYWbjif077Wij+rqYWXbDfWI7FJc2ahbZ+ovT7K+wKNdfI7OAzwT3PwP8vYk2Lfm8hsLMzgOuBz7s7pXNtGnJ5yGs+uL3O13UzOtGtv4CZwMr3b2kqYVRrr9DEvXe6jBuxI5qeZPY0QTfDeZNB6YH9w2YESz/L1DchrWdSmzT9Q1gcXCb0qi+q4BlxI6AeAU4uQ3rGxK87pKghoRaf8Hrdyb2xd4tbl6k649YKG0Gaoj9Sv08kAs8B7wV/O0ZtO0LzD7Q57WN6ltNrH+94XN4T+P6mvs8tFF9DwWfrzeIfbn3SaT1F8x/oOFzF9e2zdffkd40xISISJLriF1DIiJyCBQEIiJJTkEgIpLkFAQiIklOQSAikuQUBCIBM6uz949s2mojWZrZoPiRK0USSVrUBYgkkH3uPjbqIkTamrYIRA4iGE/+VjN7LbgdFcwfaGbPBYOiPWdmA4L5BcH4/kuC28nBU6Wa2W8sdh2Kp82sU9D+ajNbHjzPzIjepiQxBYHIezo16hq6JG5ZubuPB+4G7gjm3U1sOO7RxAZsuzOYfycw12OD3h1H7IxSgGHADHc/GigDPhbMvwEYFzzP9HDemkjzdGaxSMDMKty9axPz1wFnuvuaYMDALe6ea2bbiQ17UBPM3+zueWZWChS6+/645xgEPOPuw4Lp64F0d/+Rmf0TqCA2SurjHgyYJ9JWtEUg0jLezP3m2jRlf9z9Ot7bR3cBsbGbjgcWBSNairQZBYFIy1wS9/fl4P5LxEa7BLgMeDG4/xzwZQAzSzWznOae1MxSgP7u/gLwLaA78IGtEpEw6ZeHyHs62fsvQP5Pd284hDTTzF4l9uPp0mDe1cB9ZvZNoBS4Ipj/NeBeM/s8sV/+XyY2cmVTUoGHzawbsVFdf+HuZa30fkRaRPsIRA4i2EdQ7O7bo65FJAzqGhIRSXLaIhARSXLaIhARSXIKAhGRJKcgEBFJcgoCEZEkpyAQEUly/x96v+7TURU3uwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 98.50488901138306%\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate neural networks\n",
    "nn_bow_metrics = Neural_Network_Classify(bow_train_features, \n",
    "                                          train_labels, \n",
    "                                          bow_test_features, \n",
    "                                          test_labels, \n",
    "                                          bow_train_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7556632161140442, Accuracy: 32.93073654174805%\n",
      "Epoch: 2, Loss: 0.6971099376678467, Accuracy: 33.42371368408203%\n",
      "Epoch: 3, Loss: 0.6180824041366577, Accuracy: 91.96450805664062%\n",
      "Epoch: 4, Loss: 0.5235825777053833, Accuracy: 89.79541778564453%\n",
      "Epoch: 5, Loss: 0.431026816368103, Accuracy: 88.29183959960938%\n",
      "Epoch: 6, Loss: 0.3544023931026459, Accuracy: 88.73551940917969%\n",
      "Epoch: 7, Loss: 0.2998507022857666, Accuracy: 90.36233520507812%\n",
      "Epoch: 8, Loss: 0.25663143396377563, Accuracy: 93.51737976074219%\n",
      "Epoch: 9, Loss: 0.2202076017856598, Accuracy: 96.05619812011719%\n",
      "Epoch: 10, Loss: 0.19065894186496735, Accuracy: 98.0280990600586%\n",
      "Epoch: 11, Loss: 0.16851812601089478, Accuracy: 99.45772552490234%\n",
      "Epoch: 12, Loss: 0.15150964260101318, Accuracy: 99.85210418701172%\n",
      "Epoch: 13, Loss: 0.13478706777095795, Accuracy: 99.92605590820312%\n",
      "Epoch: 14, Loss: 0.11722756177186966, Accuracy: 99.90140533447266%\n",
      "Epoch: 15, Loss: 0.09929285943508148, Accuracy: 99.92605590820312%\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate neural networks\n",
    "nn_tfidf_metrics = Neural_Network_Classify(tfidf_train_features, \n",
    "                                            train_labels, \n",
    "                                            tfidf_test_features, \n",
    "                                            test_labels, \n",
    "                                            tfidf_train_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and evaluate neural networks\n",
    "nn_avgwv_metrics = Neural_Network_Classify(avg_wv_train_features, \n",
    "                                            train_labels, \n",
    "                                            avg_wv_test_features, \n",
    "                                            test_labels, \n",
    "                                            avg_wv_train_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that stores all the accuracy information\n",
    "performance_dict = {}\n",
    "\n",
    "for me in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "    performance_dict[me] = {}\n",
    "    for m in [\"mnb\",\"dt\",\"rf\", \"nn\"]:\n",
    "        performance_dict[me][m] = {}\n",
    "        for f in [\"bow\",\"tfidf\",\"avgwv\"]:\n",
    "            exec('performance_dict[\"{}\"][\"{}\"][\"{}\"] = {}_{}_metrics[\"{}\"]'.format(me, m, f, m, f, me))\n",
    "        \n",
    "#Accuracy Matrix\n",
    "print(\"\\n\\033[1;31mAccuracy Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"accuracy\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\",\n",
    "                                            \"nn\":\"Neural Network\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#Precision Matrix\n",
    "print(\"\\n\\033[1;31mPrecision Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"precision\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\",\n",
    "                                            \"nn\":\"Neural Network\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#Recall Matrix\n",
    "print(\"\\n\\033[1;31mRecall Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"recall\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\",\n",
    "                                            \"nn\":\"Neural Network\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))\n",
    "\n",
    "#F1 Score Matrix\n",
    "print(\"\\n\\033[1;31mF1 Score Metrix\\n\\033[0m\")\n",
    "print(pd.DataFrame(performance_dict[\"f1\"]).rename(columns={\"mnb\":\"Naive Bayes\", \n",
    "                                            \"dt\":\"Decision Tree\", \n",
    "                                            \"rf\":\"Random Forest\",\n",
    "                                            \"nn\":\"Neural Network\"}, \n",
    "                                   index={\"bow\":\"Bag-of-words\", \n",
    "                                          \"tfidf\":\"TFIDF\", \n",
    "                                          \"avgwv\":\"Word2Vec\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for this lab. See how feature generation and model classifiers improve our result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
