{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import gensim\n",
    "from gensim import corpora,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>season</th>\n",
       "      <th>brand</th>\n",
       "      <th>author of review</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "      <th>review text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>A Dtacher</td>\n",
       "      <td>Kristin Anderson</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>September 13, 2015</td>\n",
       "      <td>Detachment was the word of the day at A Dtache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>A.F. Vandevorst</td>\n",
       "      <td>Luke Leitch</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>October 1, 2015</td>\n",
       "      <td>You heard this collection coming long before y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>A.L.C.</td>\n",
       "      <td>Kristin Anderson</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>September 21, 2015</td>\n",
       "      <td>August saw the announcement of big news for A....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>A.P.C.</td>\n",
       "      <td>Nicole Phelps</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>October 3, 2015</td>\n",
       "      <td>They call me the king of basics, Jean Touitou ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>A.W.A.K.E.</td>\n",
       "      <td>Maya Singer</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>October 21, 2015</td>\n",
       "      <td>Natalia Alaverdian is a designer with a lot of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Zo Jordan</td>\n",
       "      <td>Maya Singer</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>September 19, 2015</td>\n",
       "      <td>Water, water, everywhere, / nor any drop to dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Zuhair Murad</td>\n",
       "      <td>Amy Verner</td>\n",
       "      <td>PARIS</td>\n",
       "      <td>October 4, 2015</td>\n",
       "      <td>From a new Paris showroom, Zuhair Murad came a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1205</td>\n",
       "      <td>Luke Leitch</td>\n",
       "      <td>LONDON</td>\n",
       "      <td>September 19, 2015</td>\n",
       "      <td>Fashion and Instagram are such (often sacchari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.1 Phillip Lim</td>\n",
       "      <td>Maya Singer</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>September 14, 2015</td>\n",
       "      <td>Let other New York City fashion designers toas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>6397</td>\n",
       "      <td>Kristin Anderson</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>September 14, 2015</td>\n",
       "      <td>Flower power? Yep, the power to make a convert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year   season            brand  author of review  location  \\\n",
       "0     2016  Spring        A Dtacher  Kristin Anderson  NEW YORK   \n",
       "1     2016  Spring  A.F. Vandevorst       Luke Leitch     PARIS   \n",
       "2     2016  Spring           A.L.C.  Kristin Anderson  NEW YORK   \n",
       "3     2016  Spring           A.P.C.     Nicole Phelps     PARIS   \n",
       "4     2016  Spring       A.W.A.K.E.       Maya Singer  NEW YORK   \n",
       "..     ...     ...              ...               ...       ...   \n",
       "429   2016  Spring        Zo Jordan       Maya Singer    LONDON   \n",
       "430   2016  Spring     Zuhair Murad        Amy Verner     PARIS   \n",
       "431   2016  Spring             1205       Luke Leitch    LONDON   \n",
       "432   2016  Spring  3.1 Phillip Lim       Maya Singer  NEW YORK   \n",
       "433   2016  Spring             6397  Kristin Anderson  NEW YORK   \n",
       "\n",
       "                    time                                        review text  \n",
       "0     September 13, 2015  Detachment was the word of the day at A Dtache...  \n",
       "1        October 1, 2015  You heard this collection coming long before y...  \n",
       "2     September 21, 2015  August saw the announcement of big news for A....  \n",
       "3        October 3, 2015  They call me the king of basics, Jean Touitou ...  \n",
       "4       October 21, 2015  Natalia Alaverdian is a designer with a lot of...  \n",
       "..                   ...                                                ...  \n",
       "429   September 19, 2015  Water, water, everywhere, / nor any drop to dr...  \n",
       "430      October 4, 2015  From a new Paris showroom, Zuhair Murad came a...  \n",
       "431   September 19, 2015  Fashion and Instagram are such (often sacchari...  \n",
       "432   September 14, 2015  Let other New York City fashion designers toas...  \n",
       "433   September 14, 2015  Flower power? Yep, the power to make a convert...  \n",
       "\n",
       "[434 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fashion.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Detachment was the word of the day at A Dtacher (yes, like the labels name, bien sr). Designer Mona Kowalska loves the high concept, and one imagines that today detachment included being unconcerned with the gaze of others. Kowalskas woman, both as she appears on the runway and the real world, dresses for herself. Her intensely arty bend, and taste for clothes that match it, make A Dtacher a cultishly beloved brand among certain shoppers. This season, Kowalska presented them with a lineup of relatively playful offerings.\\rThe collection opened with a pair of midi dresses in an Indonesian-inspired floral print, which reemerged later imagined with allover Pop white polka dots. Elsewhere came cardigans in an uncanny kind of amoxicillin pink that you imagined the A Dtacher woman wearing with tongue firmly in cheek (they had Kawakubo-esque allover holes, to boot). The popcorn knits were pretty fun, too.\\rThe choice to use hardier materials lent dresses eccentric volumes, but also led to a lineup that often felt frumpy, albeit fashionably so. At times the clothes lacked the excitement and want-it-now appeal of Kowalskas Spring collection a year ago. Still, when you looked around the room at todays show and spotted women from all walks of life wearing A Dtacher clothes from various seasons gone by, you could be sure theyd find plenty to like here, too.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = df['review text'].tolist()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "    \n",
    "# Remove stopwords.\n",
    "docs = [[token for token in doc if token not in stopwords.words('english')] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=10)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detachment',\n",
       " 'word',\n",
       " 'day',\n",
       " 'dtacher',\n",
       " 'yes',\n",
       " 'like',\n",
       " 'label',\n",
       " 'name',\n",
       " 'bien',\n",
       " 'sr',\n",
       " 'designer',\n",
       " 'mona',\n",
       " 'kowalska',\n",
       " 'love',\n",
       " 'high',\n",
       " 'concept',\n",
       " 'one',\n",
       " 'imago',\n",
       " 'today',\n",
       " 'detachment',\n",
       " 'included',\n",
       " 'unconcerned',\n",
       " 'gaze',\n",
       " 'others',\n",
       " 'kowalskas',\n",
       " 'woman',\n",
       " 'appears',\n",
       " 'runway',\n",
       " 'real',\n",
       " 'world',\n",
       " 'dress',\n",
       " 'intensely',\n",
       " 'arty',\n",
       " 'bend',\n",
       " 'taste',\n",
       " 'clothes',\n",
       " 'match',\n",
       " 'make',\n",
       " 'dtacher',\n",
       " 'cultishly',\n",
       " 'beloved',\n",
       " 'brand',\n",
       " 'among',\n",
       " 'certain',\n",
       " 'shopper',\n",
       " 'season',\n",
       " 'kowalska',\n",
       " 'presented',\n",
       " 'lineup',\n",
       " 'relatively',\n",
       " 'playful',\n",
       " 'offering',\n",
       " 'collection',\n",
       " 'opened',\n",
       " 'pair',\n",
       " 'midi',\n",
       " 'dress',\n",
       " 'indonesian',\n",
       " 'inspired',\n",
       " 'floral',\n",
       " 'print',\n",
       " 'reemerged',\n",
       " 'later',\n",
       " 'imagined',\n",
       " 'allover',\n",
       " 'pop',\n",
       " 'white',\n",
       " 'polka',\n",
       " 'dot',\n",
       " 'elsewhere',\n",
       " 'came',\n",
       " 'cardigan',\n",
       " 'uncanny',\n",
       " 'kind',\n",
       " 'amoxicillin',\n",
       " 'pink',\n",
       " 'imagined',\n",
       " 'dtacher',\n",
       " 'woman',\n",
       " 'wearing',\n",
       " 'tongue',\n",
       " 'firmly',\n",
       " 'cheek',\n",
       " 'kawakubo',\n",
       " 'esque',\n",
       " 'allover',\n",
       " 'hole',\n",
       " 'boot',\n",
       " 'popcorn',\n",
       " 'knit',\n",
       " 'pretty',\n",
       " 'fun',\n",
       " 'choice',\n",
       " 'use',\n",
       " 'hardier',\n",
       " 'material',\n",
       " 'lent',\n",
       " 'dress',\n",
       " 'eccentric',\n",
       " 'volume',\n",
       " 'also',\n",
       " 'led',\n",
       " 'lineup',\n",
       " 'often',\n",
       " 'felt',\n",
       " 'frumpy',\n",
       " 'albeit',\n",
       " 'fashionably',\n",
       " 'time',\n",
       " 'clothes',\n",
       " 'lacked',\n",
       " 'excitement',\n",
       " 'want',\n",
       " 'appeal',\n",
       " 'kowalskas',\n",
       " 'spring',\n",
       " 'collection',\n",
       " 'year',\n",
       " 'ago',\n",
       " 'still',\n",
       " 'looked',\n",
       " 'around',\n",
       " 'room',\n",
       " 'today',\n",
       " 'show',\n",
       " 'spotted',\n",
       " 'woman',\n",
       " 'walk',\n",
       " 'life',\n",
       " 'wearing',\n",
       " 'dtacher',\n",
       " 'clothes',\n",
       " 'various',\n",
       " 'season',\n",
       " 'gone',\n",
       " 'could',\n",
       " 'sure',\n",
       " 'theyd',\n",
       " 'find',\n",
       " 'plenty',\n",
       " 'like',\n",
       " 'floral_print',\n",
       " 'polka_dot',\n",
       " 'spring_collection',\n",
       " 'year_ago']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 13812\n",
      "Number of documents: 434\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_token = sorted(dictionary.items(),key=lambda k:k[0], reverse = False)\n",
    "unique_token = [token.encode('utf8') for (ID,token) in sort_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matrix = gensim.matutils.corpus2dense(corpus,num_terms=len(dictionary),dtype = 'int')\n",
    "matrix = matrix.T #transpose the matrix \n",
    "\n",
    "#convert the numpy matrix into pandas data frame\n",
    "matrix_df = pd.DataFrame(matrix, columns=unique_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic:\n",
      "\"dress\",\"collection\",\"look\",\"designer\",\"show\",\"one\",\"like\",\"woman\",\"new\",\"way\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"dress\",\"collection\",\"like\",\"new\",\"one\",\"designer\",\"show\",\"look\",\"season\",\"piece\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"one\",\"dress\",\"look\",\"skirt\",\"collection\",\"clothes\",\"price\",\"show\",\"said\",\"fashion\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"collection\",\"new\",\"look\",\"designer\",\"one\",\"pajama\",\"spring\",\"like\",\"girl\",\"show\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"collection\",\"print\",\"new\",\"one\",\"designer\",\"fashion\",\"skirt\",\"show\",\"jacket\",\"dress\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"collection\",\"dress\",\"one\",\"designer\",\"new\",\"like\",\"season\",\"look\",\"piece\",\"show\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"dress\",\"collection\",\"show\",\"new\",\"like\",\"woman\",\"one\",\"designer\",\"also\",\"look\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"dress\",\"collection\",\"like\",\"one\",\"designer\",\"season\",\"look\",\"new\",\"spring\",\"skirt\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"dress\",\"fashion\",\"new\",\"look\",\"collection\",\"show\",\"like\",\"one\",\"piece\",\"also\"\n",
      "\n",
      "\n",
      "Top 10 words for topic:\n",
      "\"dress\",\"collection\",\"show\",\"look\",\"one\",\"designer\",\"like\",\"black\",\"spring\",\"came\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "\n",
    "lda.print_topics(1) #V matrix, topic matrix\n",
    "import re\n",
    "for i,topic in lda.print_topics(10):\n",
    "    print(f'Top 10 words for topic:')\n",
    "    print(\",\".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -1.6925.\n",
      "[([(0.007368192, 'collection'),\n",
      "   (0.0072387243, 'dress'),\n",
      "   (0.0057083596, 'one'),\n",
      "   (0.0050948323, 'designer'),\n",
      "   (0.004014598, 'new'),\n",
      "   (0.003943154, 'like'),\n",
      "   (0.0037891471, 'season'),\n",
      "   (0.0037601248, 'look'),\n",
      "   (0.0034064255, 'piece'),\n",
      "   (0.0034017665, 'show'),\n",
      "   (0.0033320962, 'print'),\n",
      "   (0.0031883754, 'spring'),\n",
      "   (0.0029935937, 'clothes'),\n",
      "   (0.0029183226, 'fashion'),\n",
      "   (0.0027469853, 'also'),\n",
      "   (0.002728212, 'skirt'),\n",
      "   (0.0026745878, 'came'),\n",
      "   (0.0026285083, 'way'),\n",
      "   (0.0025617925, 'made'),\n",
      "   (0.00255415, 'jacket')],\n",
      "  -0.8672698489330274),\n",
      " ([(0.008715183, 'dress'),\n",
      "   (0.006274551, 'collection'),\n",
      "   (0.0057854783, 'show'),\n",
      "   (0.0051714787, 'look'),\n",
      "   (0.00513138, 'one'),\n",
      "   (0.004209192, 'designer'),\n",
      "   (0.0041447515, 'like'),\n",
      "   (0.0035183674, 'black'),\n",
      "   (0.0034818603, 'spring'),\n",
      "   (0.0031616231, 'came'),\n",
      "   (0.0029542125, 'season'),\n",
      "   (0.0029510811, 'clothes'),\n",
      "   (0.0029410562, 'piece'),\n",
      "   (0.0028534424, 'print'),\n",
      "   (0.0028327357, 'white'),\n",
      "   (0.0027918487, 'also'),\n",
      "   (0.0027559197, 'new'),\n",
      "   (0.0027454554, 'said'),\n",
      "   (0.0027232692, 'color'),\n",
      "   (0.0026806188, 'skirt')],\n",
      "  -0.8757724069226386),\n",
      " ([(0.0076140873, 'dress'),\n",
      "   (0.006792825, 'collection'),\n",
      "   (0.006428125, 'look'),\n",
      "   (0.005348675, 'designer'),\n",
      "   (0.005030224, 'show'),\n",
      "   (0.0043272763, 'one'),\n",
      "   (0.0035133585, 'like'),\n",
      "   (0.0033138713, 'woman'),\n",
      "   (0.0032447919, 'new'),\n",
      "   (0.0031606876, 'way'),\n",
      "   (0.0029616766, 'well'),\n",
      "   (0.0029515151, 'season'),\n",
      "   (0.0029260025, 'spring'),\n",
      "   (0.0029212143, 'black'),\n",
      "   (0.0028750957, 'time'),\n",
      "   (0.0027884282, 'piece'),\n",
      "   (0.0027396614, 'jacket'),\n",
      "   (0.0026850533, 'fashion'),\n",
      "   (0.0026151463, 'clothes'),\n",
      "   (0.0025509412, 'skirt')],\n",
      "  -0.883289257231081),\n",
      " ([(0.008331193, 'dress'),\n",
      "   (0.007919547, 'collection'),\n",
      "   (0.0057124714, 'like'),\n",
      "   (0.0053059924, 'one'),\n",
      "   (0.0052635865, 'designer'),\n",
      "   (0.0049830885, 'season'),\n",
      "   (0.0046423743, 'look'),\n",
      "   (0.0044685346, 'new'),\n",
      "   (0.0042912513, 'spring'),\n",
      "   (0.004175006, 'skirt'),\n",
      "   (0.004136145, 'white'),\n",
      "   (0.0036933383, 'piece'),\n",
      "   (0.003688928, 'show'),\n",
      "   (0.0034688576, 'silk'),\n",
      "   (0.0034358404, 'back'),\n",
      "   (0.0034075442, 'clothes'),\n",
      "   (0.0032838797, 'print'),\n",
      "   (0.003215776, 'said'),\n",
      "   (0.0031275637, 'made'),\n",
      "   (0.0029710724, 'jacket')],\n",
      "  -0.8896322542074471),\n",
      " ([(0.007664632, 'dress'),\n",
      "   (0.0069662873, 'collection'),\n",
      "   (0.005594706, 'like'),\n",
      "   (0.0054792305, 'new'),\n",
      "   (0.0052146483, 'one'),\n",
      "   (0.005100112, 'designer'),\n",
      "   (0.004786102, 'show'),\n",
      "   (0.004073105, 'look'),\n",
      "   (0.003460774, 'season'),\n",
      "   (0.0033598861, 'piece'),\n",
      "   (0.0031991757, 'way'),\n",
      "   (0.0030802058, 'jacket'),\n",
      "   (0.0030252277, 'also'),\n",
      "   (0.003006673, 'said'),\n",
      "   (0.002916331, 'fashion'),\n",
      "   (0.0027801315, 'black'),\n",
      "   (0.0026801398, 'brand'),\n",
      "   (0.0026760811, 'print'),\n",
      "   (0.0026633658, 'today'),\n",
      "   (0.0025024917, 'made')],\n",
      "  -0.9454387167579729),\n",
      " ([(0.008296325, 'dress'),\n",
      "   (0.007423736, 'collection'),\n",
      "   (0.0058389404, 'show'),\n",
      "   (0.0054463875, 'new'),\n",
      "   (0.0044289934, 'like'),\n",
      "   (0.0043665594, 'woman'),\n",
      "   (0.003861834, 'one'),\n",
      "   (0.003809669, 'designer'),\n",
      "   (0.0035122104, 'also'),\n",
      "   (0.0035092104, 'look'),\n",
      "   (0.0032568865, 'way'),\n",
      "   (0.0031836475, 'said'),\n",
      "   (0.0029677702, 'spring'),\n",
      "   (0.002915357, 'season'),\n",
      "   (0.0026897213, 'black'),\n",
      "   (0.0026210193, 'runway'),\n",
      "   (0.002462016, 'high'),\n",
      "   (0.002448633, 'made'),\n",
      "   (0.002387587, 'white'),\n",
      "   (0.0023816023, 'would')],\n",
      "  -0.9774020736191457),\n",
      " ([(0.00556431, 'collection'),\n",
      "   (0.004792737, 'print'),\n",
      "   (0.0046749576, 'new'),\n",
      "   (0.0036491286, 'one'),\n",
      "   (0.0032616938, 'designer'),\n",
      "   (0.0032227896, 'fashion'),\n",
      "   (0.0029528856, 'skirt'),\n",
      "   (0.0029500464, 'show'),\n",
      "   (0.002671985, 'jacket'),\n",
      "   (0.0026607506, 'dress'),\n",
      "   (0.002571814, 'like'),\n",
      "   (0.0024376158, 'season'),\n",
      "   (0.002236419, 'way'),\n",
      "   (0.0021967054, 'time'),\n",
      "   (0.0021780997, 'spring'),\n",
      "   (0.0021477258, 'le'),\n",
      "   (0.0021087218, 'color'),\n",
      "   (0.0020231097, 'look'),\n",
      "   (0.0020201672, 'scott'),\n",
      "   (0.0018356461, 'new_york')],\n",
      "  -1.4198274434394162),\n",
      " ([(0.0054617273, 'dress'),\n",
      "   (0.005056947, 'fashion'),\n",
      "   (0.004646822, 'new'),\n",
      "   (0.0045446027, 'look'),\n",
      "   (0.0045187157, 'collection'),\n",
      "   (0.004266974, 'show'),\n",
      "   (0.0039088367, 'like'),\n",
      "   (0.0034069924, 'one'),\n",
      "   (0.003285747, 'piece'),\n",
      "   (0.0032782156, 'also'),\n",
      "   (0.0028825484, 'woman'),\n",
      "   (0.0025582071, 'clothes'),\n",
      "   (0.0023444635, 'pant'),\n",
      "   (0.0023438837, 'silk'),\n",
      "   (0.0022601795, 'way'),\n",
      "   (0.0022152613, 'made'),\n",
      "   (0.0021949483, 'black'),\n",
      "   (0.00216152, 'watermelon'),\n",
      "   (0.0021568795, 'designer'),\n",
      "   (0.002110167, 'skirt')],\n",
      "  -2.0320157501854927),\n",
      " ([(0.0049727503, 'collection'),\n",
      "   (0.0040850337, 'new'),\n",
      "   (0.0040054424, 'look'),\n",
      "   (0.0036160622, 'designer'),\n",
      "   (0.0027337135, 'one'),\n",
      "   (0.002604659, 'pajama'),\n",
      "   (0.0025389967, 'spring'),\n",
      "   (0.0024866061, 'like'),\n",
      "   (0.0023856782, 'girl'),\n",
      "   (0.0023575209, 'show'),\n",
      "   (0.0021822087, 'thing'),\n",
      "   (0.002165383, 'white'),\n",
      "   (0.0021124748, 'came'),\n",
      "   (0.002042343, 'said'),\n",
      "   (0.0020319477, 'nonoo'),\n",
      "   (0.0020317868, 'cibani'),\n",
      "   (0.002014114, 'first'),\n",
      "   (0.0020094633, 'way'),\n",
      "   (0.0019319622, 'woman'),\n",
      "   (0.0019205376, 'inspiration')],\n",
      "  -3.2670925271343934),\n",
      " ([(0.0039336337, 'one'),\n",
      "   (0.003669357, 'dress'),\n",
      "   (0.0033704946, 'look'),\n",
      "   (0.003145397, 'skirt'),\n",
      "   (0.002498173, 'collection'),\n",
      "   (0.0024187898, 'clothes'),\n",
      "   (0.0022687814, 'price'),\n",
      "   (0.0022412497, 'show'),\n",
      "   (0.0021268118, 'said'),\n",
      "   (0.002094159, 'fashion'),\n",
      "   (0.0019474752, 'macdonald'),\n",
      "   (0.0018586931, 'high'),\n",
      "   (0.0018340074, 'like'),\n",
      "   (0.0018261005, 'season'),\n",
      "   (0.0016827405, 'first'),\n",
      "   (0.0016649561, 'came'),\n",
      "   (0.0016450597, 'coat'),\n",
      "   (0.0016320511, 'today'),\n",
      "   (0.0016296342, 'car'),\n",
      "   (0.0016287399, 'felder')],\n",
      "  -4.766855417725604)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = lda.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lda = lda[corpus] #transform lda model\n",
    "\n",
    "#convert corpus_lda to numpy matrix\n",
    "U_matrix_lda = gensim.matutils.corpus2dense(corpus_lda,num_terms=10).T\n",
    "\n",
    "#write U_matrix into pandas dataframe and output\n",
    "U_matrix_lda_df = pd.DataFrame(U_matrix_lda)\n",
    "U_matrix_lda_df.to_csv('U_matrix_lda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 13812)\n",
      "(434, 10)\n"
     ]
    }
   ],
   "source": [
    "print(matrix_df.shape)\n",
    "print(U_matrix_lda_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus) #fit tfidf model\n",
    "corpus_tfidf = tfidf[corpus] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic: \n",
      "\"show\",\"new\",\"woman\",\"season\",\"print\",\"silk\",\"white\",\"brand\",\"black\",\"jacket\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "\n",
    "\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=10)\n",
    "\n",
    "import re\n",
    "for i,topic in lsi.print_topics(1):\n",
    "    print(f'Top 10 words for topic: ')\n",
    "    print(\",\".join(re.findall('\".*?\"',topic)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lsi = lsi[corpus_tfidf] #transform lda model\n",
    "\n",
    "#convert corpus_lsi to numpy matrix\n",
    "U_matrix_lsi = gensim.matutils.corpus2dense(corpus_lsi,num_terms=10).T\n",
    "\n",
    "#write U_matrix into pandas dataframe and output\n",
    "pd.DataFrame(U_matrix_lsi).to_csv('U_matrix_lsi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
